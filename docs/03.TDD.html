<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="English" xml:lang="English">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="JJ Merelo" />
  <title>MLOps-text/03.TDD.md</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="mlops.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Test driven data science</h1>
<p class="author">JJ Merelo</p>
<p class="date">27/5/2022</p>
</header>
<h1 id="test-driven-development-in-data-science">Test driven development in data science</h1>
<h2 id="tldr">TL;DR</h2>
<p>Test-driven development, or simply development that uses extensive testing, is essential to ensure quality in all phases of a data science pipeline, from data extraction and munging to results. This chapter is an introduction to testing and how to profitably use it to save time and enhance adaptability. Before testing, we’ll need to interiorize best practices in project and model design.</p>
<h2 id="testing-in-etl-workflows">Testing in ETL workflows</h2>
<p>Machine learning starts with the ETL phase: Extract, Transform and Load where you need to grab the data that’s going to be used to train and test your model. In this phase, we are going to need already a test-driven approach to ascertain that all phases (extraction, transformation) occur according to our preconceptions.</p>
<p>In general, this is a part of the process that benchmark-based ML tutorials do not pay much attention to. ETL is reduced to loading your data in a Python data frame. However, in real-world ML ETL is the most important part, and also a part of the process that needs to be heavily automated so that it works as intended and as long as possible.</p>
<p>What we will do is to explain test-driven development along with ETL techniques, so that you start to familiarize yourself with them and put them to work later in the rest of the phases of ML.</p>
<h2 id="extracting-information-for-machine-learning">Extracting information for machine learning</h2>
<p>Data is Out There. Generally, in a way that’s not too easy to obtain. It might be in one of these forms.</p>
<ul>
<li>Non-processable formats, like PDF. Yes, it’s non-processable. Don’t even try. You might get lucky and get some numbers, but that’s that. Tabular data is going to be hard, tabular data in fancy tables even harder. Just forget it.</li>
<li>Websites in semi-structured form. This is going to be found generally in press releases, or even mandatory information. This can be obtained via scraping, that is, extracting information according to the web structure or the kind of words or symbols that surround it. Scraping, however, is an arcane art and you’d better allot it quite an amount of time, because it involves many tricks, even more so if the site does not like to be scraped (happens a lot in administration/government sites). We’ll devote a bit of time to this one, later on.</li>
<li>Processable formats: CSV and others. Sometimes you get lucky and find the precise data in open data portals. You will still need to transform it, but if you’re lucky it will always have the same URL and it will be easy to extract by simply downloading.</li>
<li>APIs: application interfaces are the best; in some cases open data portals will offer them, in others, like social networks or GitHub, they will offer you loads of data in easily accessible way. You will need to obtain a token, and there will be some limitations when downloading, but other than that, offers a semantic interface. The main issue here will be to respect terms of service regarding storing/republishing, as well as controlling the request or other (like download size) limits.</li>
</ul>
<p>In all cases, you will need testing; in the case of scraping, you <em>need</em> testing. Let’s devote some time to that one.</p>
<h2 id="scraping-for-fun-and-data-science">Scraping for fun and data science</h2>
<p>Webs do not want to be scraped. If they had wanted to be scraped, they would have published data in a processable format to start with. And they do so for entirely legitimate reasons, like avoiding denial of service attacks, or simply making data a bit more obscure by having people work manually to extract it. Of course, avoiding copyright issues is also another reason.</p>
<p>In some cases, they do <em>not</em> want to be scraped, and do not want you to process that information, and even more so to publish it. So you might want to take a look at the terms of service (TOS) for the web you want to process before giving it a try. At any rate, scraping does not do anything that cannot be done manually, so personal or research use is OK in most cases. And you <em>always</em> mention source. If not for any other reason, to actually maintain the <em>source</em>, as it keep it flowing. It is not going to be useful if you can scrape it just once, so be polite about it by storing whatever you have already processed and don’t keep downloading all the stuff over and over again.</p>
<p>Scraping is defined as extracting structured information from web sources. That implies a series of steps, every one of which need some specific techniques, so we have to take a look at all the mechanisms that are implicated in the actual web.</p>
<p>It all starts with an HTTP request, generally a <code>GET</code> request, with a specific URL; this request goes through and is received by a server. In most cases, the page will be hosted by a CDN, a content delivery network; in some cases, this CDN will perform some checks on the requesting entity to rule out automatic bots. Eventually, the request is processed but it might include a redirection (HTTP status 3xx, generally 301), so the URL returned will be a <em>different</em> one (and which one will depend on many factors including the source of the request).</p>
<p>Eventually, you obtain a HTML page that’s part of your request. However, the modern web is essentially a platform for running programs, so the actual information might or might not be there. Pages will be rendered in the browser as a DOM, document object model, and this DOM will visually show the information we’re requesting, with a certain structure. But this information may, or may not, be contained in the same document (because, via so-called <em>iframes</em>, it might be actually in some other documents) or (hopefully) just contained in the DOM. This DOM might be the same every time a page is rendered, it might not.</p>
<p>Every one of these steps contains usually standard procedures to defeat scrapers, which is why scraping is an arcane art needing specific tools to take care of. We’ll devote a bit of time (and examples) to every one of them.</p>
<h3 id="obtaining-an-url-to-download-data">Obtaining an URL to download data</h3>
<p>In some very lucky cases URLs follow some specific pattern, so you can just generate them serially and you’re done; in some cases, you need to find out what the URL is, but once you do it, you are good to go.</p>
<blockquote>
<p>From now on, we are going to use different examples, either from the Portuguese INE or from Ukraine war data as published by the ministry of Defense of that country.</p>
</blockquote>
<p>This fragment of a <a href="../code/deno/download.ts">program in Deno</a>, a framework for interpreting Javascript and typescript, will download a specific page from the INE in Portugal:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode typescript"><code class="sourceCode typescript"><a class="sourceLine" id="cb1-1" title="1"><span class="im">import</span> puppeteer <span class="im">from</span> <span class="st">&quot;https://deno.land/x/puppeteer@9.0.0/mod.ts&quot;</span><span class="op">;</span></a>
<a class="sourceLine" id="cb1-2" title="2"><span class="im">import</span> <span class="op">{</span> cheerio <span class="op">}</span> <span class="im">from</span> <span class="st">&quot;https://deno.land/x/cheerio@1.0.4/mod.ts&quot;</span><span class="op">;</span></a>
<a class="sourceLine" id="cb1-3" title="3"></a>
<a class="sourceLine" id="cb1-4" title="4"><span class="kw">const</span> url <span class="op">=</span> <span class="st">&#39;https://www.ine.pt/xportal/xmain?xpid=INE&amp;xpgid=ine_indicadores&amp;userLoadSave=Load&amp;userTableOrder=11804&amp;tipoSeleccao=1&amp;contexto=pq&amp;selTab=tab1&amp;submitLoad=true&#39;</span><span class="op">;</span></a>
<a class="sourceLine" id="cb1-5" title="5"></a>
<a class="sourceLine" id="cb1-6" title="6"><span class="cf">try</span> <span class="op">{</span></a>
<a class="sourceLine" id="cb1-7" title="7">    <span class="kw">const</span> browser <span class="op">=</span> <span class="cf">await</span> <span class="va">puppeteer</span><span class="op">.</span><span class="fu">launch</span>()<span class="op">;</span></a>
<a class="sourceLine" id="cb1-8" title="8">    <span class="kw">const</span> page <span class="op">=</span> <span class="cf">await</span> <span class="va">browser</span><span class="op">.</span><span class="fu">newPage</span>()<span class="op">;</span></a>
<a class="sourceLine" id="cb1-9" title="9">    <span class="cf">await</span> <span class="va">page</span><span class="op">.</span><span class="fu">goto</span>(url)<span class="op">;</span></a></code></pre></div>
<p>The URL is contained in line 4, and contains a main section, and then a series of queries that redirect to the specific one page we are looking for.</p>
<blockquote>
<p>Those queries might contain random variables, or, even worse, hashes or session tokens that have been generated by some other client or server program. You’ll have to use a different strategy in that case.</p>
</blockquote>
<p>In the case of Ukraine MoD data, the URL can be generated this way:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" title="1"><span class="kw">def</span> download(driver, day, month):</a>
<a class="sourceLine" id="cb2-2" title="2">    url <span class="op">=</span> <span class="ss">f&#39;https://www.mil.gov.ua/en/news/2022/</span><span class="sc">{</span>month<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>day<span class="sc">}</span><span class="ss">/the-total-combat-losses-of-the-enemy-from-24-02-to-</span><span class="sc">{</span>day<span class="sc">:02}</span><span class="ss">-</span><span class="sc">{</span>month<span class="sc">}</span><span class="ss">/&#39;</span></a></code></pre></div>
<p>It follows some specific pattern that includes the month and the day of the month, in one of the instances padded with zeros (<code>day:02</code>). This may be part of the URL, or part of the queries. In any case, if there is a systematic way of obtaining the URL, that is what should be tried first.</p>
<p>However, that is the case only some times. That data above, for instance, does not contain combat losses for every day. If you want that kind of data, you need to go to the <a href="https://www.mil.gov.ua/">original in Ukrainian</a>. And in this case it is impossible to know, from the shape of the URLs, which ones contain the data we want.</p>
<p>But scraping is 90% technology, and the remaining 90%, ingenuity. It so happens that all URLs with Russian losses contains the word <code>vtrati</code>, which means <code>losses</code>.</p>
<h2 id="see-also">See also</h2>
<p>Despite its title, Thoughtful Machine Learning is a great test-driven approach to data science <span class="citation" data-cites="kirk2014thoughtful">[@kirk2014thoughtful]</span></p>
<h2 id="references">References</h2>
</body>
</html>
